#　什么是负载均衡？

> 本文作者：[程序员鱼皮](https://yuyuanweb.feishu.cn/wiki/Abldw5WkjidySxkKxU2cQdAtnah)
>
> 本站地址：[https://codefather.cn](https://codefather.cn)

大家好，我是鱼皮。

周末在家写代码，无意中跟朋友提了下 LB，还说 LB 好的呱呱叫。

朋友笑了笑，问我 LB 是谁？

![](https://pic.yupi.icu/5563/202311071359055.png)

我解释道：LB 它可不是活人，而是目前企业开发中常用的技术 —— 负载均衡，下面让我给你讲讲吧！

## **负载均衡**

### **介绍**

假如我们刚刚上线一个网站，最多只有 10 个人同时访问，那么只需要把网站放到一台服务器上就够了，又叫 **单机部署** ：

![](https://pic.yupi.icu/5563/202311071359061.jpeg)

随着我们网站的不断宣传，可能出现上万用户同时访问的情况。由于一台服务器的 CPU、内存、带宽等资源都是有限的，无法同时支撑那么多用户。因此可能需要多台服务器一起来扛，分摊用户的请求，你一半我一半，又叫 **集群部署**：

![](https://pic.yupi.icu/5563/202311071359032.jpeg)

但这样有个问题，每个服务器都有一个不同的 IP 地址，想把用户的请求分摊到不同的服务器上，总不能让用户自己去输入不同的 IP 访问吧？

因此，我们还需要一台 **代理服务器** ，对外提供 **唯一** 的入口，**统一** 接受用户的请求。再根据请求（或流量）的 **特征** ，依据一定的 **算法** ，将请求转发到内部的服务器集群中，如图：

![](https://pic.yupi.icu/5563/202311071359043.jpeg)

这样对于用户来说，始终通过一个域名访问网站即可，他完全感知不到你的网站到底部署到多少台服务器上、也不关心它是如何部署的。

这便是 **负载均衡**（Load Balancing 简称 LB），是企业中最重要的高并发解决方案之一。

### **作用**

负载均衡最直观的作用就是提高系统的并发度，说人话就是允许更多人同时访问了。

它还可以提高整个系统的可用性，假如集群中有一台服务器挂了，代理服务器只要不再把请求转发给它就行了，集群中的其他服务器仍然能够正常地接受和处理请求。

此外，负载均衡还能够减少用户等待响应的时间、通过并行提高整个系统的处理能力等。

![](https://pic.yupi.icu/5563/202311071359035.jpeg)

### **分类**

虽然通过代理服务器转发请求能够提升整个系统的并发访问数，但不要忘了，代理服务器本身的资源也是有限的啊！像比较常用的 Nginx 代理，能有个几万并发就撑死了。如果同时访问的用户量再大一点，不就忍不下了么？！

![](https://pic.yupi.icu/5563/202311071359048.png)

而且代理服务器也存在挂掉的可能性，一旦它挂了，后果不堪设想。

因此，我们可以将负载均衡进行分类，针对不同的场景来选择相对合适的实现方式。

比较常见的分类方法是：根据 **计算机网络七层模型** ，按照负载均衡所属的网络层次去区分。

下面这张计算机网络模型图还是很棒的：

![](https://pic.yupi.icu/5563/202311071359285.jpeg)

有关计算机网络的知识非本文重点，大家可以自行去了解，不懂也没关系，可以接着往下看。

无论是哪层负载均衡，都需要有代理服务器，并且对外提供唯一的 IP 地址，然后根据算法将请求转发到目标服务器（实际处理请求的服务器）。只不过实现转发的原理和逻辑不同罢了。

### **二层负载均衡**

二层指数据链路层，数据以数据帧的形式通过交换机进行传输。

这一层是没有 IP 地址概念的，只能用 MAC 地址对机器进行区分。因此负载均衡服务器会通过一个虚拟 MAC 地址接受请求，并通过改写报文目标 MAC 地址的方式将请求转发到具有不同 MAC 地址的目标机器。

![](https://pic.yupi.icu/5563/202311071359846.jpeg)

二层负载均衡最原始、性能极高。但只能通过硬件设备实现，比如 F5、Array 等，价格十分昂贵。

主要的底层实现方式就是 PPP 捆绑和链路聚合技术，这里不做赘述，对于开发同学来说，大家一般也接触不到二层负载均衡。

### **三层负载均衡**

三层即网络层，这一层开始有了 IP 地址的概念，可以根据 IP 地址路由网络。

这一层的负载均衡设备会对外提供一个虚拟的 IP 地址（VIP）以接收请求，然后根据算法将请求转发到 IP 地址不同的目标机器。

![](https://pic.yupi.icu/5563/202311071359142.jpeg)

和二层一样，三层负载均衡也是通过硬件设备实现，成本也比较高。

### **四层负载均衡**

四层即传输层，除了包含三层的 IP 地址信息之外，还多了源目端口号的概念，可以区分同一机器上不同的应用。

由于得到了更多的信息，这一层的负载均衡会更加灵活，对外提供一个虚拟的 IP 地址 + 端口号来接收请求，然后根据算法将请求转发到不同目标机器的不同端口上。

![](https://pic.yupi.icu/5563/202311071359129.jpeg)

四层负载均衡可以通过软件实现，比如主流且开源的 LVS（Linux Virtual Server），底层可选多种负载模式，比如 NAT（网络地址转换）、DR（直接路由）、TUN（隧道）。

四层负载均衡的优点是：一方面是性能很高、比较稳定，支撑个十几万、几十万并发不成问题；另一方面是成本低、纯软件实现，因此在企业中的应用很广泛。

### **七层负载均衡**

七层指应用层，是计算机网络模型的最上层，因此能得到请求最为详细的信息，比如 HTTP 请求头等。

可以根据域名或主机 IP + 端口接收请求，并通过应用层信息（请求头、Cookie 等）灵活地转发请求，比如将手机端用户转发到服务器 A、桌面端用户转发到服务器 B 等。

![](https://pic.yupi.icu/5563/202311071359732.jpeg)

这种方式实现成本最低，也最为灵活，因此也是我们应用开发人员最常用的了。

实现方式多种多样，比如主流的 Nginx、HAProxy 都可以，写个配置基本就能转发请求了，大部分情况下性能也够用了。

再提一下所属于这层的 `DNS 负载均衡` ，基于 DNS 域名解析服务，可以将同一个域名解析为不同的 IP 地址，从而让用户访问到不同服务器上的项目。

这种方式实现起来不难，但转发逻辑不够灵活，而且 DNS 存在缓存，不利于修改。

------

除了上面讲到的这些，负载均衡还有很多学问，比如负载均衡算法（比如常用的静态轮询、动态连接数等）、高可用等，这些大家自行了解和实践下就好了，具体场景具体分析。